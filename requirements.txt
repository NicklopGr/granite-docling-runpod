# Granite-Docling-258M RunPod Dependencies

# Transformers for reliable inference (VLLM has multimodal issues)
transformers>=4.40.0
accelerate

# Flash Attention for faster inference
flash-attn

# DocTags to HTML conversion
docling-core

# Image processing
pillow

# RunPod serverless SDK
runpod

# PyTorch (should come with base image but explicit)
torch
